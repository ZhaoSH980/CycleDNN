{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import Evaluation_par as ep\n",
    "import model.CycleDNN_v1 as md\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, choose_cell='0 1', clean_threshold=0.02, dataset_name='c12345', epoch=0, gamma=0.95, lr=0.01, momentum=0.9, n_epochs=4000, num_cell=2, num_temperature=10, step_size=300, weight_decay=0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--num_cell\", type=int, default=2, help=\"number of cellline\")\n",
    "parser.add_argument(\"--choose_cell\", type=str, default='0 1', help=\"choose cellline\")\n",
    "parser.add_argument(\"--num_temperature\", type=int, default=10, help=\"number of temperature\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=0, help=\"epoch to start training from\")\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=4000, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--dataset_name\", type=str, default=\"c12345\", help=\"name of the dataset\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=128, help=\"size of the batches\")\n",
    "\n",
    "parser.add_argument(\"--lr\", type=float, default=0.01, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"adam: momentum\")\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0, help=\"adam: weight_decay\")\n",
    "parser.add_argument(\"--step_size\", type=int, default=300, help=\"adam: step_size\")\n",
    "parser.add_argument(\"--gamma\", type=float, default=0.95, help=\"adam: gamma\")\n",
    "\n",
    "parser.add_argument(\"--clean_threshold\", type=float, default=0.02, help=\"clean threshold to filter \")\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "#opt = parser.parse_args()\n",
    "print(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\data\\%s.csv'% opt.dataset_name)\n",
    "df = np.asarray(df)\n",
    "dfc = np.asarray(df)\n",
    "cc = opt.choose_cell.split()\n",
    "choose_cell = []\n",
    "for i in range(len(cc)):\n",
    "    choose_cell.append(int(cc[i]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "clean_thers = opt.clean_threshold\n",
    "j = 0\n",
    "for i in range(df.shape[0]):\n",
    "    k = (df[i,:]-clean_thers<0).sum().item()\n",
    "    if k>0:\n",
    "        dfc = np.delete(dfc, i-j, 0)\n",
    "        j = j +1\n",
    "\n",
    "df = dfc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_data = np.zeros((df.shape[0] ,opt.num_cell,opt.num_temperature),dtype=float)\n",
    "k = 0\n",
    "for i in choose_cell:\n",
    "    df_data[:,k,:] = np.asarray(df[:,i*10:i*10+10])\n",
    "    k=k+1\n",
    "\n",
    "CETSA_cell = torch.Tensor(df_data)\n",
    "#viewCETSA_cell = df_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_index = np.array(list(range(0,df.shape[0])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_list, test_list, train_label, test_label = train_test_split(train_index, train_index, test_size=0.3,random_state=202)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "CETSA_train = CETSA_cell[train_list,:,:]\n",
    "CETSA_test = CETSA_cell[test_list,:,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "path = \"./result/\"\n",
    "dirs = os.listdir(path)\n",
    "exp_num = str(len(dirs)+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, input, label):\n",
    "        super(Dataset).__init__()\n",
    "        self.input = input\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.input[item,:,:], self.label[item,:,:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\REDME\\AppData\\Local\\Temp/ipykernel_25192/2597821341.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  DataLoader(Dataset(torch.tensor(CETSA_train).float(), torch.tensor(CETSA_train).float()),\n"
     ]
    }
   ],
   "source": [
    "train_iter = \\\n",
    "    DataLoader(Dataset(torch.tensor(CETSA_train).float(), torch.tensor(CETSA_train).float()),\n",
    "                    batch_size=opt.batch_size,\n",
    "                    shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\REDME\\AppData\\Local\\Temp/ipykernel_25192/3488319039.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  DataLoader(Dataset(torch.tensor(CETSA_test).float(), torch.tensor(CETSA_test).float()),\n"
     ]
    }
   ],
   "source": [
    "test_iter = \\\n",
    "    DataLoader(Dataset(torch.tensor(CETSA_test).float(), torch.tensor(CETSA_test).float()),\n",
    "                    batch_size=opt.batch_size,\n",
    "                    shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "en_all = []\n",
    "de_all = []\n",
    "for i in range(opt.num_cell):\n",
    "    en = md.Encoder()\n",
    "    de = md.Decoder()\n",
    "    if torch.cuda.is_available():\n",
    "        en.cuda()\n",
    "        de.cuda()\n",
    "    en_all.append(en)\n",
    "    de_all.append(de)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "en_op_all = []\n",
    "de_op_all = []\n",
    "en_sch_all = []\n",
    "de_sch_all = []\n",
    "for i in range(opt.num_cell):\n",
    "    en_optimizer = torch.optim.SGD(en_all[i].parameters(), lr=opt.lr,momentum=opt.momentum,weight_decay=opt.weight_decay)\n",
    "    de_optimizer = torch.optim.SGD(de_all[i].parameters(), lr=opt.lr,momentum=opt.momentum,weight_decay=opt.weight_decay)\n",
    "    en_scheduler=torch.optim.lr_scheduler.StepLR(en_optimizer,step_size=opt.step_size,gamma=opt.gamma)\n",
    "    de_scheduler=torch.optim.lr_scheduler.StepLR(de_optimizer,step_size=opt.step_size,gamma=opt.gamma)\n",
    "    en_op_all.append(en_optimizer)\n",
    "    de_op_all.append(de_optimizer)\n",
    "    en_sch_all.append(en_scheduler)\n",
    "    de_sch_all.append(de_scheduler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def plot_train_loss(exp_num, e_num,c_line,c_tem):\n",
    "    csv_path = './result/exp' + str(exp_num)+ '/result/train_loss.csv'\n",
    "    jpg_path = './result/exp' + str(exp_num)+ '/result/train_loss_'+str(e_num)+'.jpg'\n",
    "    train_loss = pd.read_csv(csv_path)\n",
    "    train_loss = np.asarray(train_loss)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(c_line):\n",
    "        for j in range(c_line):\n",
    "            plt.plot(train_loss[:,c_line*c_line+1],train_loss[:,i*c_line+j] ,label = '%s_Loss' % (chr(ord('A') + i) + chr(ord('A') + j)))\n",
    "\n",
    "    plt.plot(train_loss[:,c_line*c_line+1],train_loss[:,i*c_line+j+1] ,label =  'Z_Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(jpg_path)\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def plot_test_eva_loss(exp_num, e_num,c_line,c_tem):\n",
    "    csv_path = './result/exp' + str(exp_num)+ '/result/test_eva.csv'\n",
    "    test_eva_plot = pd.read_csv(csv_path)\n",
    "    test_eva_plot = np.asarray(test_eva_plot)\n",
    "    loss_str = ['MAPE_Loss','MSE_Loss','RMSE_Loss','MAE_Loss']\n",
    "    c_all = c_line*c_line\n",
    "    for i in range(c_all):\n",
    "        jpg_path = './result/exp' + str(exp_num)+ '/result/test_eva_self_'+str(i)+'_epcho'+str(e_num)+'.jpg'\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for j in range(4):\n",
    "            plt.plot(test_eva_plot[i::c_all,5],test_eva_plot[i::c_all,j] ,label = (str(i) + loss_str[j]))\n",
    "\n",
    "        plt.legend()\n",
    "        plt.savefig(jpg_path)\n",
    "        plt.close()\n",
    "\n",
    "    for i in range(4):\n",
    "        jpg_path = './result/exp' + str(exp_num)+ '/result/test_eva_compare_'+str(i)+'_epcho'+str(e_num)+'.jpg'\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for j in range(c_all):\n",
    "            plt.plot(test_eva_plot[j::c_all,5],test_eva_plot[j::c_all,i] ,label = (str(i) + (chr(ord('A') + j//c_line))))\n",
    "        plt.legend()\n",
    "        plt.savefig(jpg_path)\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train(en_all, de_all, en_op_all, de_op_all, en_sch_all, de_sch_all, train_iter, test_iter,\n",
    "          loss_function, num_epochs, num_cell, c_tem):\n",
    "    #num_cell = 1\n",
    "    c_line = num_cell\n",
    "    c_all = c_line * c_line\n",
    "    text_cell_trans = []\n",
    "    for j in range(c_all):\n",
    "        text = (chr(ord('A') + j // c_line) + chr(ord('A') + j % c_line))\n",
    "        text_cell_trans.append(text)\n",
    "\n",
    "    lowest_test_loss = float('inf')\n",
    "\n",
    "    # best_MAPE_testAB,best_MSE_testAB ,best_RMSE_testAB,best_MAE_testAB\n",
    "    best_test_acc = 100 * np.ones([c_all, 5])\n",
    "    best_train_acc = 100 * np.ones([c_all, 5])\n",
    "\n",
    "    ex_test = np.zeros([c_all, 4])\n",
    "    ex_train = np.zeros([c_all, 4])\n",
    "\n",
    "    path = \"./result/\"\n",
    "    dirs = os.listdir(path)\n",
    "    new_path = path + 'exp' + str(len(dirs) + 1)\n",
    "    os.mkdir(new_path)\n",
    "    print(new_path)\n",
    "    new_path_weights = new_path + \"/weight\"\n",
    "    new_path_results = new_path + \"/result\"\n",
    "    os.mkdir(new_path_weights)\n",
    "    os.mkdir(new_path_results)\n",
    "    train_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        test_eva = np.zeros([c_all, 6])\n",
    "        train_eva = np.zeros([c_all, 6])\n",
    "        train_l_sum = np.zeros([c_all + 1, 6])\n",
    "        train_loss = np.zeros([c_all + 1])\n",
    "        train_loss_1 = np.zeros(c_all + 2)\n",
    "        loss_z = 0.00\n",
    "        n = 0\n",
    "\n",
    "        for X, Y in train_iter:\n",
    "            if torch.cuda.is_available():\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "            Z_all = torch.tensor(np.zeros([num_cell, X.shape[0], 500]))\n",
    "            total_loss = 0.00\n",
    "            #num_cell = 1\n",
    "            for k1 in range(num_cell):\n",
    "                for k2 in range(num_cell):\n",
    "                    x = X[:, k1, :]\n",
    "                    y = X[:, k2, :]\n",
    "                    z_out = en_all[k1](x)\n",
    "                    z_out = z_out.squeeze(1)\n",
    "                    y_hat = de_all[k2](z_out)\n",
    "                    y_hat = y_hat.squeeze(1)\n",
    "\n",
    "                    train_loss[num_cell * k1 + k2] = loss_function(y_hat, y).item()\n",
    "                    train_loss_1[num_cell * k1 + k2] += train_loss[num_cell * k1 + k2].item()\n",
    "\n",
    "                    total_loss += loss_function(y_hat, y)\n",
    "                    #print(loss_function(y_hat, y))\n",
    "                    #a = (str(train_loss_1[num_cell*k1+k2]))\n",
    "                    #print(text_cell_trans[num_cell*k1+k2]+a)\n",
    "                Z_all[k1, :, :] = en_all[k1](x).squeeze(1)\n",
    "            #num_cell = 1\n",
    "            loss_z = 0.00\n",
    "            for k1 in range(num_cell):\n",
    "                for k2 in range(num_cell):\n",
    "                    loss_z += loss_function(en_all[k1](x).squeeze(1), en_all[k2](x).squeeze(1))\n",
    "\n",
    "            train_loss_1[c_all] += loss_z.item()\n",
    "\n",
    "            total_loss += loss_z / 2\n",
    "\n",
    "            for j in range(num_cell):\n",
    "                en_op_all[j].zero_grad()\n",
    "                de_op_all[j].zero_grad()\n",
    "\n",
    "            n += y.shape[0]\n",
    "            total_loss.backward()\n",
    "\n",
    "            for j in range(num_cell):\n",
    "                en_op_all[j].step()\n",
    "                de_op_all[j].step()\n",
    "\n",
    "            #ex_MAPE_testBA,ex_MSE_testBA ,ex_RMSE_testBA,ex_MAE_testBA\n",
    "        if epoch == 0:\n",
    "            for k1 in range(num_cell):\n",
    "                for k2 in range(num_cell):\n",
    "                    ex_test[num_cell * k1 + k2, :] = ep.ex_accurary(test_iter, loss_function, k1, k2)\n",
    "                    ex_train[num_cell * k1 + k2, :] = ep.ex_accurary(train_iter, loss_function, k1, k2)\n",
    "\n",
    "            with open(str(new_path_results + '/ex_test_train.csv'), 'w', newline='') as myFile:\n",
    "                myWriter = csv.writer(myFile)\n",
    "                myWriter.writerows(ex_test)\n",
    "                myWriter.writerows(ex_train)\n",
    "\n",
    "        for j in range(num_cell):\n",
    "            en_sch_all[j].step()\n",
    "            de_sch_all[j].step()\n",
    "\n",
    "        # MAPE,MSE,RMSE,MAE,Loss\n",
    "        h = 0\n",
    "        for k1 in range(num_cell):\n",
    "            for k2 in range(num_cell):\n",
    "                test_eva[h, 0:5] = ep.net_accurary2(test_iter, loss_function, en_all[k1], de_all[k2], k1, k2)\n",
    "                train_eva[h, 0:5] = ep.net_accurary2(train_iter, loss_function, en_all[k1], de_all[k2], k1, k2)\n",
    "                test_eva[h, 5] = epoch\n",
    "                train_eva[h, 5] = epoch\n",
    "                h = h + 1\n",
    "\n",
    "        if epoch == 0:\n",
    "            with open(str(new_path_results + '/test_eva.csv'), 'w') as myFile:\n",
    "                myWriter = csv.writer(myFile)\n",
    "            with open(str(new_path_results + '/train_eva.csv'), 'w') as myFile:\n",
    "                myWriter = csv.writer(myFile)\n",
    "            with open(str(new_path + '/parameter.txt'), 'w') as f:\n",
    "                print(en_all[0], file=f)\n",
    "            with open(str(new_path + '/parameter.txt'), 'a') as f:\n",
    "                print(de_all[0], file=f)\n",
    "                print(opt, file=f)\n",
    "\n",
    "        with open(str(new_path_results + '/test_eva.csv'), 'a', newline='') as myFile:\n",
    "            myWriter = csv.writer(myFile)\n",
    "            myWriter.writerows(test_eva)\n",
    "\n",
    "        with open(str(new_path_results + '/train_eva.csv'), 'a', newline='') as myFile:\n",
    "            myWriter = csv.writer(myFile)\n",
    "            myWriter.writerows(train_eva)\n",
    "\n",
    "        for i in range(c_all):\n",
    "            if best_test_acc[i, 1] > test_eva[i, 1]:\n",
    "                best_test_acc[i, 0:4] = test_eva[i, 0:4]\n",
    "                best_test_acc[i, 4] = epoch + 1\n",
    "                k = i // num_cell\n",
    "                j = i % num_cell\n",
    "                torch.save(en_all[k],\n",
    "                           str(new_path_weights + '/CycleDNN_v01_withZ_MSE_best_en' + str(k) + '_' + str(i) + '.pkl'))\n",
    "                torch.save(de_all[j],\n",
    "                           str(new_path_weights + '/CycleDNN_v01_withZ_MSE_best_de' + str(j) + '_' + str(i) + '.pkl'))\n",
    "\n",
    "            if best_train_acc[i, 1] > train_eva[i, 1]:\n",
    "                best_train_acc[i, 0:4] = train_eva[i, 0:4]\n",
    "                best_train_acc[i, 4] = epoch + 1\n",
    "\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            for i in range(num_cell):\n",
    "                torch.save(en_all[i], str(new_path_weights + '/CycleDNN_v01_withZ_MSE_en' + str(i) + '_' + str(\n",
    "                    epoch + 1) + '.pkl'))\n",
    "                torch.save(de_all[i], str(new_path_weights + '/CycleDNN_v01_withZ_MSE_de' + str(i) + '_' + str(\n",
    "                    epoch + 1) + '.pkl'))\n",
    "\n",
    "        with open(str(new_path_results + '/best_test_acc.csv'), 'w', newline='') as myFile:\n",
    "            myWriter = csv.writer(myFile)\n",
    "            myWriter.writerows(best_test_acc)\n",
    "\n",
    "        with open(str(new_path_results + '/best_train_acc.csv'), 'w', newline='') as myFile:\n",
    "            myWriter = csv.writer(myFile)\n",
    "            myWriter.writerows(best_train_acc)\n",
    "\n",
    "        for k1 in range(num_cell):\n",
    "            for k2 in range(num_cell):\n",
    "                train_loss_1[num_cell * k1 + k2] = train_loss_1[num_cell * k1 + k2] / n\n",
    "        train_loss_1[c_all] = train_loss_1[c_all] / n\n",
    "        train_loss_1[c_all + 1] = epoch + 1\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch: %d' % (epoch + 1))\n",
    "            for k1 in range(num_cell):\n",
    "                for k2 in range(num_cell):\n",
    "                    text = (chr(ord('A') + k1) + chr(ord('A') + k2)) + 'loss:'\n",
    "                    print(text + '%.8f' % (train_loss_1[num_cell * k1 + k2]))\n",
    "        print('epoch: %d' % (epoch + 1))\n",
    "        if epoch == 0:\n",
    "            with open(str(new_path_results + '/train_loss.csv'), 'w') as myFile:\n",
    "                myWriter = csv.writer(myFile)\n",
    "\n",
    "        with open(str(new_path_results + '/train_loss.csv'), 'a', newline='') as myFile:\n",
    "            myWriter = csv.writer(myFile)\n",
    "            myWriter.writerow(train_loss_1)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            plot_train_loss(exp_num, epoch, c_line, c_tem)\n",
    "            plot_test_eva_loss(exp_num, epoch, c_line, c_tem)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./result/exp10\n",
      "epoch: 1\n",
      "AAloss:0.00234763\n",
      "ABloss:0.00190181\n",
      "BAloss:0.00238785\n",
      "BBloss:0.00190425\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "AAloss:0.00012992\n",
      "ABloss:0.00016917\n",
      "BAloss:0.00021555\n",
      "BBloss:0.00009203\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "AAloss:0.00010280\n",
      "ABloss:0.00014965\n",
      "BAloss:0.00018888\n",
      "BBloss:0.00007588\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "AAloss:0.00007523\n",
      "ABloss:0.00013680\n",
      "BAloss:0.00017215\n",
      "BBloss:0.00005878\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "AAloss:0.00005055\n",
      "ABloss:0.00012592\n",
      "BAloss:0.00015835\n",
      "BBloss:0.00003580\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 51\n",
      "AAloss:0.00004156\n",
      "ABloss:0.00012006\n",
      "BAloss:0.00015204\n",
      "BBloss:0.00002876\n",
      "epoch: 51\n",
      "epoch: 52\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "AAloss:0.00003551\n",
      "ABloss:0.00011627\n",
      "BAloss:0.00014868\n",
      "BBloss:0.00002703\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "AAloss:0.00003008\n",
      "ABloss:0.00011280\n",
      "BAloss:0.00014440\n",
      "BBloss:0.00002563\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "AAloss:0.00002645\n",
      "ABloss:0.00011266\n",
      "BAloss:0.00014256\n",
      "BBloss:0.00002580\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25192/3715242941.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m train_loss = train(en_all, de_all, en_op_all, de_op_all, en_sch_all, de_sch_all, train_iter, test_iter,\n\u001B[0m\u001B[0;32m      2\u001B[0m                    loss_function, opt.n_epochs, opt.num_cell, opt.num_temperature)\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25192/1367479290.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(en_all, de_all, en_op_all, de_op_all, en_sch_all, de_sch_all, train_iter, test_iter, loss_function, num_epochs, num_cell, c_tem)\u001B[0m\n\u001B[0;32m     50\u001B[0m                     \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m                     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m                     \u001B[0mz_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0men_all\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m                     \u001B[0mz_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mz_out\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m                     \u001B[0my_hat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mde_all\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz_out\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\EE5907\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\OD\\OneDrive - njust.edu.cn\\CycleDNN\\model\\CycleDNN_v1.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     27\u001B[0m         \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m         \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m         \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfc2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m         \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m         \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfc3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\EE5907\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\EE5907\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\EE5907\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mlinear\u001B[1;34m(input, weight, bias)\u001B[0m\n\u001B[0;32m   1845\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1846\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1847\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1848\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss = train(en_all, de_all, en_op_all, de_op_all, en_sch_all, de_sch_all, train_iter, test_iter,\n",
    "                   loss_function, opt.n_epochs, opt.num_cell, opt.num_temperature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}